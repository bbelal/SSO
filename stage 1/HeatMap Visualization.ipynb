{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Localization Using Heat Maps of Class Activation\n",
    "\n",
    "In this notebook, we provide the source code of localizing pneumonia using heat maps.\n",
    "Here we use the implementation of the work in \"Grad-CAM: Visual\n",
    "Explanations from Deep Networks via Gradient-based Localization.[1]\"\n",
    "\n",
    "[1] Ramprasaath R. Selvaraju et al., arXiv (2017), https://arxiv.org/abs/1610.02391."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Loading libraries\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 220, 220, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 220, 220, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 110, 110, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 110, 110, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4610      \n",
      "=================================================================\n",
      "Total params: 707,586\n",
      "Trainable params: 447,426\n",
      "Non-trainable params: 260,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First, build the model\n",
    "img_width = 220\n",
    "img_height = 220\n",
    "img_channels = 3\n",
    "weights='imagenet'\n",
    "img_dim = (img_width, img_height, img_channels)\n",
    "\n",
    "base_model = VGG16(\n",
    "              weights=weights,\n",
    "              include_top=False,\n",
    "              input_shape=img_dim)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "i=0\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    model.add(layer)\n",
    "    i+=1\n",
    "    if(i>6):\n",
    "        break\n",
    "\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secound, load the trained weights\n",
    "model.load_weights('Checkpoints/model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and  preprocessing the image to be diagnosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './HeatMap//1.jpeg'\n",
    "img = image.load_img(img_path, target_size=(220, 220))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0) # Adds a dimension to transform the array into a batch of size (1, 220, 220, 3)\n",
    "x /=255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative probability:  0.00014787173  || Positive probability:  0.99985206\n"
     ]
    }
   ],
   "source": [
    "# Classify/Diagnose the image\n",
    "preds = model.predict(x)\n",
    "print('Negative probability: ', preds[0][0], ' || Positive probability: ', preds[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Grad-CAM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "positive_pneumonia_output = model.output[:, 1]\n",
    "last_conv_layer = model.get_layer('conv2d_2') #Output feature map of the conv2d_2 layer\n",
    "\n",
    "# Gradient of the “Positive pneumonia” class with regard to the output feature map of conv2d_2\n",
    "grads = K.gradients(positive_pneumonia_output, last_conv_layer.output)[0]\n",
    "\n",
    "# Vector of shape (128,), where each entry is the mean intensity of the gradient over a specific feature-map channel\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# Lets you access the values of the quantities you just defined: pooled_grads and the output feature map of conv2d_2, given\n",
    "# a sample image\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "# Values of these two quantities, as Numpy arrays, given the sample input image x\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "# Multiplies each channel in the feature-map array by “how important this channel is” with regard to the “pneumonia” class\n",
    "for i in range(128):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "# The channel-wise mean of the resulting feature map is the heatmap of the class activation.\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap post-processing\n",
    "\n",
    "For visualization purposes, we’ll need to normalize the heatmap between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1db2bb33400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Superimposing the heatmap with the original picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(img_path)\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap) # Converts the heatmap to RGB\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img #0.4 here is a heatmap intensity factor.\n",
    "cv2.imwrite('./HeatMap/rr_cam.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
